{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing basic packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Importing sklearn modules\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, precision_score, recall_score,roc_curve, roc_auc_score, auc, classification_report\n",
    "from sklearn import ensemble, linear_model, neighbors, svm, tree, neural_network\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import svm,model_selection, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset \n",
    "diabetes= pd.read_csv(\"C:/Users/kezen/OneDrive/Documents/Microsoft/data/diabetes.csv\", delimiter=\",\", header=\"infer\")\n",
    "diabetes.drop(columns= [\"PatientID\"], inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
    "label = 'Diabetic'\n",
    "x = diabetes[features].values \n",
    "y =diabetes[label].values\n",
    "\n",
    "# split data 70% to training and test dataset: 70% to training and 30% to testing dataset \n",
    "x_train,x_test,y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state = 100) # random_state ensures reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up different machine learning models \n",
    "models = []\n",
    "models.append((\"LR\", LogisticRegression()))\n",
    "models.append((\"LDA\", LinearDiscriminantAnalysis()))\n",
    "models.append((\"KNN\", KNeighborsClassifier()))\n",
    "models.append((\"NB\", GaussianNB()))\n",
    "models.append((\"CART\", DecisionTreeClassifier()))\n",
    "models.append((\"RF\", RandomForestClassifier()))\n",
    "models.append((\"Adaboost\", AdaBoostClassifier()))\n",
    "models.append((\"XGBoost\", XGBClassifier(use_label_encoder= False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: Mean = 0.78, STD: 0.017392\n",
      "LDA: Mean = 0.79, STD: 0.010451\n",
      "KNN: Mean = 0.84, STD: 0.007284\n",
      "NB: Mean = 0.79, STD: 0.016201\n",
      "CART: Mean = 0.89, STD: 0.00943\n",
      "RF: Mean = 0.93, STD: 0.009515\n",
      "Adaboost: Mean = 0.95, STD: 0.004611\n",
      "[17:35:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:35:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:35:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:35:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:35:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:35:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:35:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:35:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:35:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:35:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost: Mean = 0.95, STD: 0.003909\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "results = []\n",
    "names = []\n",
    "scoring = \"accuracy\"\n",
    "#perform cross validation \n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits= 10, random_state= None) # set up cross validation\n",
    "    cv_results = model_selection.cross_val_score(model, x_train, y_train, scoring = scoring, cv = kfold)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    output = f\"{name}: Mean = {round(cv_results.mean(),2)}, STD: {round(cv_results.std(), 6)}\"\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost has the highest accuracy (0.95) on the traininig dataset. Therefore build final model using Adaboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot boxplot comparing the algorithms \n",
    "fig = plt.figure(figsize = (7,7))\n",
    "fig.suptitle(\"Comparison of Sensitivity Scores between different ML Algorithms\")\n",
    "ax = fig.add_subplot(111)\n",
    "box = plt.boxplot(results, patch_artist= True)\n",
    "ax.set_xticklabels(names)\n",
    "colors = ['cyan', 'lightblue', 'lightgreen', 'tan', 'pink', \"red\", \"green\", \"purple\"]\n",
    "for patch, color in zip(box[\"boxes\"], colors):\n",
    "    patch.set_facecolor(color)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kezen\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:57:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual_values</th>\n",
       "      <th>Predicted_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3366</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual_values  Predicted_values\n",
       "2473              0                 0\n",
       "470               0                 0\n",
       "1262              0                 0\n",
       "100               1                 1\n",
       "3366              0                 0\n",
       "728               0                 0\n",
       "1211              0                 0\n",
       "135               0                 0\n",
       "1776              0                 0\n",
       "633               0                 0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = XGBClassifier(random_state= 100).fit(x_train, y_train)\n",
    "# make predictions on the test data set \n",
    "predictions = final_model.predict(x_test)\n",
    "# create dataframe of predictions vs actual values \n",
    "df = pd.DataFrame({\n",
    "    \"Actual_values\": y_test,\n",
    "    \"Predicted_values\": predictions\n",
    "})\n",
    "df.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.95\n",
      "Recall: 0.92\n",
      "Precision: 0.94\n",
      "Confusion Matrix: \n",
      " [[2915   91]\n",
      " [ 113 1381]]\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance \n",
    "accuracy = np.round(accuracy_score(y_test, predictions), 2)\n",
    "recall = np.round(recall_score(y_test, predictions), 2)\n",
    "precision = np.round(precision_score(y_test, predictions), 2)\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm= confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\", \"\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if tuning hyperparameters will improve performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "\n",
      "best score: 0.9647619047619047\n",
      "\best params: {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000}\n",
      "\n",
      "best model: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.3,\n",
      "              enable_categorical=False, eval_metric='logloss', gamma=0,\n",
      "              gpu_id=-1, importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.01, max_delta_step=0, max_depth=10,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=1000, n_jobs=8, num_parallel_tree=1,\n",
      "              predictor='auto', random_state=100, reg_alpha=0, reg_lambda=1,\n",
      "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
      "              use_label_encoder=False, validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "# set up hyperparameters grid\n",
    "params = { 'max_depth': [3,6,10],\n",
    "           'learning_rate': [0.01, 0.05, 0.1],\n",
    "           'n_estimators': [100, 500, 1000],\n",
    "           'colsample_bytree': [0.3, 0.5, 0.7]}\n",
    "\n",
    "# set up scoring metrics \n",
    "scoring = \"accuracy\"\n",
    "\n",
    "# set the algorithm\n",
    "alg = XGBClassifier(random_state= 100,  use_label_encoder = False, eval_metric = \"logloss\")\n",
    "\n",
    "# hyperparemeters combination\n",
    "grid_search = GridSearchCV(alg, params, scoring = scoring, cv = 3, return_train_score= True, verbose= 1)\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "#get the best hyperparameter combination \n",
    "best_params= grid_search.best_params_\n",
    "# get best score\n",
    "best_score= grid_search.best_score_\n",
    "print(\"\\nbest score:\", best_score)\n",
    "print(\"\\best params:\", best_params)\n",
    "## get the best performing model \n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"\\nbest model:\", best_model)\n",
    "\n",
    "# fit using best model\n",
    "model = best_model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual_values</th>\n",
       "      <th>Predicted_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3684</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3446</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual_values  Predicted_values\n",
       "2826              0                 1\n",
       "328               0                 1\n",
       "3684              0                 1\n",
       "262               0                 1\n",
       "494               0                 1\n",
       "2116              0                 1\n",
       "1252              0                 1\n",
       "4056              1                 1\n",
       "3035              1                 1\n",
       "3446              0                 1"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions on the test data set \n",
    "predictions = model.predict(x_test)\n",
    "# create dataframe of predictions vs actual values \n",
    "df = pd.DataFrame({\n",
    "    \"Actual_values\": y_test,\n",
    "    \"Predicted_values\": predictions\n",
    "})\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.96\n",
      "Recall: 0.93\n",
      "Precision: 0.95\n",
      "Confusion Matrix: \n",
      " [[2940   66]\n",
      " [ 108 1386]]\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      3006\n",
      "           1       0.95      0.93      0.94      1494\n",
      "\n",
      "    accuracy                           0.96      4500\n",
      "   macro avg       0.96      0.95      0.96      4500\n",
      "weighted avg       0.96      0.96      0.96      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance \n",
    "accuracy = np.round(accuracy_score(y_test, predictions), 2)\n",
    "recall = np.round(recall_score(y_test, predictions), 2)\n",
    "precision = np.round(precision_score(y_test, predictions), 2)\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm= confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\", \"\\n\", cm)\n",
    "class_report = classification_report(y_test, predictions)\n",
    "print(\"classification report:\", \"\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slight improvement in accuracy score from tuning the hyperparameters\n",
    "\n",
    "finally check if processing improves result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  [0, 1, 2, 3, 4, 5, 6]),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('onehot',\n",
      "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                                  [7])])),\n",
      "                ('xgb',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=0.3, enable_categorical=F...\n",
      "                               importance_type=None, interaction_constraints='',\n",
      "                               learning_rate=0.01, max_delta_step=0,\n",
      "                               max_depth=10, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=1000,\n",
      "                               n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
      "                               random_state=100, reg_alpha=0, reg_lambda=1,\n",
      "                               scale_pos_weight=1, subsample=1,\n",
      "                               tree_method='exact', use_label_encoder=False,\n",
      "                               validate_parameters=1, verbosity=None))])\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Define preprocessing for numeric columns (normalize them so they're on the same scale)\n",
    "numeric_features = [0,1,2,3,4,5,6]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Define preprocessing for categorical features (encode the Age column)\n",
    "categorical_features = [7]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Create preprocessing and training pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('xgb', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.3,\n",
    "              enable_categorical=False, eval_metric='logloss', gamma=0,\n",
    "              gpu_id=-1, importance_type=None, interaction_constraints='',\n",
    "              learning_rate=0.01, max_delta_step=0, max_depth=10,\n",
    "              min_child_weight=1,  monotone_constraints='()',\n",
    "              n_estimators=1000, n_jobs=8, num_parallel_tree=1,\n",
    "              predictor='auto', random_state=100, reg_alpha=0, reg_lambda=1,\n",
    "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
    "              use_label_encoder=False, validate_parameters=1, verbosity=None))])\n",
    "\n",
    "# fit the pipeline to train a extreme gradient boost  model on the training set\n",
    "model = pipeline.fit(x_train, (y_train))\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('preprocessor',\n",
       "  ColumnTransformer(transformers=[('num',\n",
       "                                   Pipeline(steps=[('scaler', StandardScaler())]),\n",
       "                                   [0, 1, 2, 3, 4, 5, 6]),\n",
       "                                  ('cat',\n",
       "                                   Pipeline(steps=[('onehot',\n",
       "                                                    OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                   [7])])),\n",
       " ('xgb',\n",
       "  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=0.3,\n",
       "                enable_categorical=False, eval_metric='logloss', gamma=0,\n",
       "                gpu_id=-1, importance_type=None, interaction_constraints='',\n",
       "                learning_rate=0.01, max_delta_step=0, max_depth=10,\n",
       "                min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "                n_estimators=1000, n_jobs=8, num_parallel_tree=1,\n",
       "                predictor='auto', random_state=100, reg_alpha=0, reg_lambda=1,\n",
       "                scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "                use_label_encoder=False, validate_parameters=1, verbosity=None))]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get feature importance \n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features 0: Pregnancies\n",
      "Features 1: PlasmaGlucose\n",
      "Features 2: DiastolicBloodPressure\n",
      "Features 3: TricepsThickness\n",
      "Features 4: SerumInsulin\n",
      "Features 5: BMI\n",
      "Features 6: DiabetesPedigree\n",
      "Features 7: Age\n",
      "Features 8: Diabetic\n"
     ]
    }
   ],
   "source": [
    "for index, name in enumerate(diabetes.columns):\n",
    "    print(f\"Features {index}: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual_values</th>\n",
       "      <th>Predicted_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4087</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4362</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual_values  Predicted_values\n",
       "2270              0                 0\n",
       "1515              0                 0\n",
       "2632              0                 0\n",
       "1379              0                 0\n",
       "3603              0                 0\n",
       "2495              0                 0\n",
       "469               0                 0\n",
       "4087              0                 0\n",
       "2680              0                 0\n",
       "4362              1                 1"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions on the test data set \n",
    "predictions = model.predict(x_test)\n",
    "# create dataframe of predictions vs actual values \n",
    "df = pd.DataFrame({\n",
    "    \"Actual_values\": y_test,\n",
    "    \"Predicted_values\": predictions\n",
    "})\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.96\n",
      "Recall: 0.93\n",
      "Precision: 0.95\n",
      "Confusion Matrix: \n",
      " [[2933   73]\n",
      " [ 108 1386]]\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      3006\n",
      "           1       0.95      0.93      0.94      1494\n",
      "\n",
      "    accuracy                           0.96      4500\n",
      "   macro avg       0.96      0.95      0.95      4500\n",
      "weighted avg       0.96      0.96      0.96      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance \n",
    "accuracy = np.round(accuracy_score(y_test, predictions), 2)\n",
    "recall = np.round(recall_score(y_test, predictions), 2)\n",
    "precision = np.round(precision_score(y_test, predictions), 2)\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm= confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\", \"\\n\", cm)\n",
    "class_report = classification_report(y_test, predictions)\n",
    "print(\"classification report:\", \"\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the ROC Curve\n",
    "\n",
    "#ROC Curve shows the curve of the true and false positive rates.\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "# get probailities of th predictions \n",
    "y_scores  = model.predict_proba(x_test)\n",
    "\n",
    "# calculate the ROC Curve \n",
    "fpr, tpr, thresholds = roc_curve(y_true= y_test, y_score= y_scores[:,1])\n",
    "# plot the 50% diagonal line \n",
    "plt.plot([0,1], [0,1], \"r--\")\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2040da8ca29d028fd77a98f656d6d33ab79db1d6e1b4800bea793ff287b05de3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
